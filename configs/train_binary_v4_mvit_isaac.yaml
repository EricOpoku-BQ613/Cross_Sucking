# configs/train_binary_v4_mvit_isaac.yaml
#
# MViTv2-S on UTK ISAAC-NG HPC cluster.
# Data is on Lustre scratch â€” clips already transferred via Globus.
#
# Key differences from RunPod config:
#   - clip_dir: absolute path on Lustre scratch
#   - out_dir: scratch space (faster I/O than home)
#   - batch_size: 16 for A100 40/80GB (double RunPod)
#   - num_workers: 8 (HPC nodes have 16-32 CPUs)
#   - accum_steps: 1 (large batch, no accumulation needed)
#
# To submit: sbatch scripts/train_isaac.slurm
# To adjust: set BATCH_SIZE=8 in SLURM script if you get a V100 (16GB)

seed: 42
device: "cuda"

data:
  train_csv: "data/manifests/train_v4.csv"
  val_csv: "data/manifests/val_v4.csv"
  clip_dir: "/lustre/isaac24/scratch/eopoku2/clips_v4"   # Globus transfer destination

  balanced_sampling: true
  filter_to_id: true
  num_workers: 8         # HPC nodes: 16-32 CPUs available
  batch_size: 16         # A100 40/80GB: batch 16 fits easily with AMP
                         # REDUCE to 8 if you get V100 (16GB)

clip:
  clip_len: 16
  fps: 12

labels:
  num_classes: 2
  class_names: ["ear", "tail"]
  id_labels: ["ear", "tail"]

model:
  backbone: "mvit_v2_s"
  pretrained: true
  head: "linear"
  head_dropout: 0.3

loss:
  name: "focal"
  gamma: 2.0
  use_class_weights: true    # 6.85x weight on tail
  label_smoothing: 0.05

optim:
  name: "adamw"
  lr: 0.00002
  weight_decay: 0.05

sched:
  name: "cosine_warmup"
  t_max: 50
  min_lr: 0.0000005
  warmup_epochs: 5
  warmup_start_lr: 0.0000005

train:
  epochs: 50
  amp: true
  grad_clip: 1.0
  log_every: 50
  out_dir: "/lustre/isaac24/scratch/eopoku2/runs/sup_binary_v4_mvit"
  metric_key: "f1_tail"
  accum_steps: 1
  early_stopping: true
  early_stopping_patience: 15
  early_stopping_min_delta: 0.001
  save_per_sample_loss: true

augmentation:
  use_trivial_augment: true
  use_mixup: true
  mixup_alpha: 0.4
